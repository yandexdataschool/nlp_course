### Word embeddings
- [__lecture slides__](../resources/slides/nlp2020_word_embeddings.pdf)
- Our videos: [__intro__](https://yadi.sk/i/BNTJG-_rwf20Gw), [__lecture__](https://yadi.sk/i/nUiHl4VPMOCz0g), [__seminar__](https://yadi.sk/i/QTcGA5mgdhS8jg)
- Lecture video from Stanford CS224N - [__intro__](https://www.youtube.com/watch?v=OQQ-W_63UgQ), [__embeddings__](https://www.youtube.com/watch?v=ERibwqs9p38) (english)


### Practice & homework
The practice for this week takes place in notebooks. Just open them and follow instructions from there.
* __Seminar:__ `./seminar.ipynb`
* __Homework:__ `./homework.ipynb`

Unless explicitly said otherwise, all subsequent weeks follow the same pattern (notebook with instructions).

If you have any difficulties with notebooks, just open them in [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yandexdataschool/nlp_course/blob/2020/week01_embeddings/seminar.ipynb).

### Lecture-blog, research thinking exercises, related papers and fun: ![NLP Course For You](https://lena-voita.github.io/nlp_course.html#preview_word_emb)
![embedding_space_walk](../resources/word_embeddings.gif)

### More materials (optional)
* On hierarchical & sampled softmax estimation for word2vec [page](http://ruder.io/word-embeddings-softmax/)
* GloVe project [page](https://nlp.stanford.edu/projects/glove/)
* FastText project [repo](https://github.com/facebookresearch/fastText)
* Another cool link that you could have shared, but decided to hesitate. Or did you?

